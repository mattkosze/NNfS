{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b1bfe72c68755f",
   "metadata": {},
   "source": [
    "# Chapter 10: Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:29:41.369046Z",
     "start_time": "2025-06-20T22:29:41.095039Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preface: Install necessary packages:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "from timeit import timeit\n",
    "from resources.classes import DenseLayer, ReLU, SoftMax, Loss, CategoricalCrossEntropy, SoftMaxCategoricalCrossEntropy, SGD, AdaGrad, RMSProp, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47c2c624a27552",
   "metadata": {},
   "source": [
    "We spent chapter nine learning about how we can calculate and apply the gradients to adjust weights & biases to ultimately reduce loss. What we ended up doing was subtracting a fraction of the gradient for each weight and bias parameter -- and that is called stochastic gradient descent (SGD). Most optimizer that we use are actually just modifications in the implementation of SGD.\n",
    "\n",
    "## Section 1: Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Anyone who's heard about optimizers before has probably heard many names -- seemingly used interchangeably -- including:\n",
    "- Stochastic Gradient Descent or SGD.\n",
    "- Vanilla Gradient Descent, Gradient Descent or GD, Batch Gradient Descent or BGD.\n",
    "- Mini-batch Gradient Descent or MBGD.\n",
    "\n",
    "However: these are not the same. SGD has historically referred to an optimizer that fits a single sample at a time. Meanwhile, BGD is an optimizer used to fit a whole dataset at once. Lastly, MBGD is an optimizer used to fit slices to a dataset, which we'd call batches in our context.\n",
    "\n",
    "As a general rule of thumb, we call slices of data **batches**. However, historically, these same slices have been referred to as **mini-batches** in the context of SGD. With that said, the field has evolved and the two are now used interchangeably to the point where we actually think of the SGD optimizer as one that assumes a batch of data.\n",
    "\n",
    "In the case of SGD, we need to choose a learning rate. From that, we then subtract:\n",
    "$$\n",
    "\\text{learningRate} \\cdot \\text{parameterGradients} \n",
    "$$ \n",
    "from the actual values. \n",
    "\n",
    "We'll walk through creating an example SGD class below -- but I've already made one and added it to the class.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb1ce69e52d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleSGD():\n",
    "    # Initialize the class\n",
    "    def __init__(self, lr=1.0):\n",
    "        # Store the learning rate; just 1 if not specified\n",
    "        self.lr = lr\n",
    "        \n",
    "    # Method to update the parameters after a backward pass\n",
    "    def updateParams(self, layer):\n",
    "        # Update values according to: -lr * parameter_gradients\n",
    "        layer.weights += -self.lr * layer.dweights\n",
    "        layer.bias += -self.lr * layer.dbiases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0506eb7feeb0f",
   "metadata": {},
   "source": [
    "The above is an early version of our SGD class! Now, to use it, we have to instantiate the object by doing \"optimizer = SGD()\" and then doing \"optimizer.updateParams(denseX)\" for each hidden layer X in our model.\n",
    "\n",
    "Again, the above is code cell is just an example implementation for convenience; we can just directly reference the SGD() class from our classes.py.\n",
    "\n",
    "With this built out, we can begin training our model in repeated iterations called epochs. An epoch simply means a full pass through all the training data. So, let's implement our model to trainable in epochs by leveraging looping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf0d52a9a085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = SGD()\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb1f6d43aac0ed",
   "metadata": {},
   "source": [
    "Now making models that are learning and performing better on their dataset -- which we can clearly see by increasing accuracy and decreasing loss. However, our accuracy seems to get stuck just below the ~.70 mark with about ~.62 loss. That tells us the model may have reached a local minimum, which we'll talk about soon. That tells us that adding epochs likely won't be very helpful at this point, and we need to work on our optimizer. The first thing we can change is the learning rate, so that's what we'll look at next!\n",
    "\n",
    "## Section 2: Learning Rates\n",
    "\n",
    "We want to apply a fraction of the gradients to the parameters in order to descend the loss value. Typically, we don't apply the full gradient value (which would just be the slope of the tangent line) because these values will typically be too large to produce meaningful improvements. Instead, we want to perform small steps, calculating the gradient and updating parameters by a negative fraction of this gradient. These small steps allow us to ensure that we are following the direction of the steepest descent -- but these can be too small, causing learning stagnation.\n",
    "\n",
    "When the learning rate is too small, the update to the parameters are too small the model may get stuck in a local minimum as opposed to actually finding the global minimum. So, how do we know if our model is at the global minimum? We know it is so when the loss reaches as close to 0 as possible -- but we frequently never reach 0 in practice, as that may cause overfitting (a topic which I assume will be talked about in a later chapter). \n",
    "\n",
    "Learning rate in itself is not enough -- you may still be getting stuck in local minimums no matter what you set it to. So, for that reason, we must introduce momentum. Momentum, in an optimizer, adds to the gradient what we, in the physical world, would call intertia. For example, if we throw a ball uphill, then with enough force or a small enough hill, the ball can roll over the crest of the hill and onto the other side.\n",
    "\n",
    "These parameters in the optimizer (such as the learning rate or momentum) are referred to as hyperparameters.\n",
    "\n",
    "If the learning rate is too big the model may start jumping around during SGD, caused by the amount of gradient applied being too large. At the extreme, this may cause a gradient explosion. A gradient explosion is where the parameter updates cause the function's output to rise instead of fall, causing the gradient and loss to increase with each step. \n",
    "\n",
    "Ultimately, choosing the correct hyperparameters will enable you to speed up the learning process and save yourself money and time. It's typically best to start with the optimizer defaults, perform a few steps, and then observe the training process when tuning different settings. However, it's always useful to have some system that actively tunes your hyperparameters even during training. One way that we do this is by using learning rate decay. \n",
    "\n",
    "## Section 3: Learning Rate Decay   \n",
    "\n",
    "The idea of learning rate decay is to start with a large learning rate (i.e. something like 1.0) and then decrease it during training. We have a few ways of going about this, and one is to decrease the learning rate in response to the loss across epochs. You can either program this by checking performance or manually adjust it once you deem it appropriate. The other way is to implement a decay rate which steadily decays the learning rate per batch or epoch.\n",
    "\n",
    "We can start by planning decay per step -- otherwise known as 1/t decaying or exponential decaying. We'll be updating the learning rate each step by the reciprocal step count function, and this will take the step and the decaying ratio and multiples them. Basically, the bigger the step is, the biggest the result of this multiplication. As the take the reciprocal, that means that our learning rate will continue decreasing by ever smaller amounts. The fraction then works out to $\\frac{1}{1 + lr * step}$, with the added 1 on the bottom ensuring that our learning rate decay will never raise the lr. Let's show how this can work in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef316aa79723c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our lr to the default for SGD (1)\n",
    "lr_init = 1.\n",
    "# Set our decay rate\n",
    "lr_decay = 0.1 \n",
    "\n",
    "# Now to code out the equation we showed above (using a lambda function for versatility)\n",
    "lr = lambda step: lr_init * (1. /(1 + lr_decay * step))\n",
    "\n",
    "# Let's see the lr at step 1\n",
    "stepA = 1\n",
    "print(f\"At step {stepA} the lr is: {lr(stepA)}\")\n",
    "\n",
    "# Let's see how that differs at step 20\n",
    "stepB = 20\n",
    "print(f\"At step {stepB} the lr is: {lr(stepB)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dddc75aba2c73c",
   "metadata": {},
   "source": [
    "In practice a decay of 0.1 would be pretty aggressive, but this gives good intuition about how it's meant to work. \n",
    "\n",
    "Now, let's update our SGD optimize class. I'll show the changes made to the SGD class below as additions to code previously written for our earlier ExampleSGD class made a few cells ago. As previously, the actual changes will be made in the classes.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc050423169e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleSGD():\n",
    "    # MODIFIED: initialize object\n",
    "    def __init__(self, lr=1., decay=0.):\n",
    "        ...\n",
    "        # Create a way to store the current learning rate, decay, and iteration/step\n",
    "        self.lr_curr = lr\n",
    "        self.decay = decay\n",
    "        self.iteration = 0\n",
    "        \n",
    "    # NEW: call to update learning rate before parameter refresh\n",
    "    def preUpdateParams(self):\n",
    "        # If there is a nonzero decay, update the lr before updating the parameters \n",
    "        if self.decay:\n",
    "            self.lr_curr = self.lr * (1./(1. + self.decay * self.iteration))\n",
    "            \n",
    "    # NEW: Call after a parameter update\n",
    "    def postUpdateParams(self):\n",
    "        self.iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3a6747d5ba139",
   "metadata": {},
   "source": [
    "Like I said, all of the above is callable through our full SGD function implemented in the classes.py file.\n",
    "\n",
    "So, let's try to train our model again, but with a decay rate of 1e-2 (0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da722e9abe66371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = SGD(decay=1e-3)\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}, lr: {optimizer.lr_curr}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.preUpdateParams()\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)\n",
    "    optimizer.postUpdateParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc95f8899694c8e",
   "metadata": {},
   "source": [
    "Now we're on the right track, with higher accuracy and the lowest loss so far. However, it is likely still possible to produce a better output, as it seems possible the model has gotten stuck in a local minimum.\n",
    "\n",
    "## Section 4: SGD with Momentum\n",
    "\n",
    "Momentum may be a solution to our problem - as it creates a rolling average of gradients over some number of updates and uses this avg. with the unique gradient at each step. This helps when a model gets stuck in a local minimum and is bouncing around in it. As we remember, the gradient as a vector points in the direction of the steepest loss ascent -- meaning the direction which, if followed, would lead to loss **increasing** the most. For that reason, we always take the negative of the gradient, as that logically would point us in the direction of the steepest loss ascent. If you understand linear algebra, I would relate it as follows: imagine you have a gradient in a 2d space as a column vector g, where g=[1,2]. Then, you have a line going up 2 and 1 to the right, and if you follow that line your loss will increase by the highest amount. Now, if we take the negative of that, we have g=[-1,-2], meaning that we have a new vector going 2 to the left, and 1 down -- which is our direction of steepest loss descent. That example really helped me intuitively understand it, so I hope it helped you too. \n",
    "\n",
    "The reason momentum is so helpful is thanks to leveraging previous movements. Pure SGD simply goes into the opposite direction of the steepest loss ascent, meaning it is possible for it to bounce between \"walls\" of a local minimum and never be able to get out. Momentum on the other hand uses the previous update's direction to influence the next update's direction, minimizing the odds of such bouncing around.\n",
    "\n",
    "We use momentum by setting a parameter between 0 and 1, representing the fraction of the previous parameter update to retain, and subtracting our actual gradient, multiplied by the learning rate. The update then contains only a portion of the gradient from preceding steps as our momentum and only a portion of the current gradient. \n",
    "\n",
    "When we set the momentum value too high, the model might stop learning at all since the direction of updates may not be able to follow the global gradient descent. \n",
    "\n",
    "The code for this is as follows: ```weight_updates = self.momentum * layer.weight_momentums - self.lr_curr * layer.dweights``` where the hyperparameter self.momentum is chosen at the start and the layer.weight_momentums start as all zeros but as changed during training as ```layer.weight_momentums = weight_updates```.\n",
    "\n",
    "The above tells us that momentum is always updated before the parameters -- so we'll add it to our updateParams() method in the SGD class. I'll show the additions here and also make changes directly in the classes.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03939526f1ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleSGD():\n",
    "    def __init__(self, lr=1., decay=0., momentum=0.):\n",
    "        ...\n",
    "        # Store the momentum in the object \n",
    "        self.momentum = momentum \n",
    "         \n",
    "    # MODIFIED: added the use of momentum\n",
    "    def updateParams(self, layer):\n",
    "        # Do if we've used momentum\n",
    "        if self.momentum:\n",
    "            # If layer does not have a momentum array, create it\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # No momentum array --> no bias array; so create it too.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "                \n",
    "            # Build weight updates with momentum\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.lr_curr * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "            \n",
    "            #Build bias updates with momentum\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.lr_curr * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "        # SGD without momentum\n",
    "        else:\n",
    "            weight_updates = -self.lr_curr * layer.dweights\n",
    "            bias_updates = -self.lr_curr * layer.dbiases\n",
    "            \n",
    "        #With updates now calculated, update both weights and biases\n",
    "        layer.weights += weight_updates\n",
    "        layer.bias += bias_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5d17fc4ad84eb",
   "metadata": {},
   "source": [
    "I've made the corresponding changes in our full SGD() class, but the above should give you a clearer picture exactly what changes have been made.\n",
    "\n",
    "Let's run our model again now, with a decay of 1e-3 and a momentum of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f95d576de29ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = SGD(decay=1e-3, momentum=0.5)\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}, lr: {optimizer.lr_curr}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.preUpdateParams()\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)\n",
    "    optimizer.postUpdateParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c8fc9a84394f6",
   "metadata": {},
   "source": [
    "We're getting there, but let's try setting the momentum to 0.9 and see how the model reactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fbfba534b32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = SGD(decay=1e-3, momentum=0.9)\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}, lr: {optimizer.lr_curr}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.preUpdateParams()\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)\n",
    "    optimizer.postUpdateParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d5d7537c81215",
   "metadata": {},
   "source": [
    "That's a massive difference!! Loss decreased by 50% from .422 to .211 -- which is a huge difference!\n",
    "\n",
    "SGD with momentum is typically one of the 2 main choices for an optimizer in practice next to the Adam optimizer. Let's talk about 2 more optimizers now! \n",
    "\n",
    "## Section 5: AdaGrad\n",
    "\n",
    "AdaGrad, short for adaptive gradient, institutes a per-parameter learning rate rather than a globally-shared rate. This has the advantage of normalizing the updates made to features -- preventing certain weights from rising disproportionally to others. AdaGrad keeps a history of previous updates and, the bigger the sum of the updates is (both pos. or neg.), then the smaller updates are made further in training. This has the benefit of allowing less-frequently updated parameters to keep-up with changes, resulting in a more effective use of neurons for training.\n",
    "\n",
    "This concept can be contained in the following two lines of code: ```cache += parm_gradient ** 2 ``` and ```parm_updates = lr * parm_gradient / (sqrt(cache) + eps)```. In this, the cache holds a history of squared gradients, and the parm_updates is a function of the learning rate multipled by the gradient and is then divided by the sqrt of the cache plus an epsilon value. This value, epsilon, is a hyperparameter preventing division by 0. It usually has a small value, such as 1e-7, which we'll default to.\n",
    "\n",
    " To implement AdaGrad, we extend our SGD optimizer class; but change the name, add an epsilon property to the object, and remove the momentum. The book completely copies over the SGD class through a copy paste, but we can just extend it and override methods instead. The only thing that changes is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107b724bdd327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED: Removing momentum from updateParams\n",
    "class ExampleAdaGrad(ExampleSGD):\n",
    "    def __init__(self, lr=1., decay=0., epsilon=1e-7):\n",
    "        ...\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def updateParams(self, layer):\n",
    "        # If layer does not contain cache arrays, create them\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "            \n",
    "        # Update cache with gradients squared\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "        \n",
    "        # Vanilla SGD parameter update & norm\n",
    "        layer.weights += -self.lr_curr * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.lr_curr * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5f6f89f503deb",
   "metadata": {},
   "source": [
    "Those are the only changes we need to make! As usual, the full class is implemented in the classes.py file. The only difference here is the full class is not written out, but instead we create an AdaGrad class which extends the SGD class, letting us use its methods in Adagrad, saving us from having to rewrite the whole class.\n",
    "\n",
    "Now, lets try out how AdaGrad works with our usual model training situation, but setting AdaGrad's decay to 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8759e7c1aed5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer as Adagrad with a decay\n",
    "optimizer = AdaGrad(decay=1e-4)\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}, lr: {optimizer.lr_curr}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.preUpdateParams()\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)\n",
    "    optimizer.postUpdateParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c401e57f0d463",
   "metadata": {},
   "source": [
    "AdaGrad also performs quite well in this situation -- although not as well as plain SGD with momentum surprisingly. But yeah, that's AdaGrad for you!\n",
    "\n",
    "## Section 6: RMSProp\n",
    "\n",
    "RMSProp is short for Root Mean Square Propagation. It's similar to AdaGrad, in the sense that it calculate an adaptive learning rate per parameter, but it's calculated differently than AdaGrad. While AdaGrad calculates the cache as ```cache += gradient**2```, RMSProp instead calculates the cache as ```cache = rho * cache + (1-rho) * gradient**2```. \n",
    "\n",
    "This is somewhat similar to both momentum in the SGD optimizer and cache in the AdaGrad -- where's it's like a per-parameter momentum, which ensure smoother changes. However, instead of always adding the gradients squared to the cache, it instead uses a moving average. This results in cache contents that move with data and don't stall.\n",
    "\n",
    "The new hyperparameter we use here is *rho*. Rho is the cache memory decay rate\n",
    "\n",
    "Here we once again can just extend the SGD class and override methods, as I'll show below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f000c44cba8dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleRMSProp(ExampleSGD):\n",
    "    # Extend the init method \n",
    "    def __init__(self, lr=1., decay=0., epsilon=1e-7, rho=0.9):\n",
    "        ...\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "        \n",
    "    # MODIFIED: added RMSProp functionality to the updateParam method    \n",
    "    def updateParams(self, layer):\n",
    "        ...\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1-self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + (1-self.rho) * layer.dbiases**2\n",
    "        \n",
    "        # Vanilla SGD parameter update & norm\n",
    "        layer.weights += -self.lr_curr * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.lr_curr * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8f68766ff8588",
   "metadata": {},
   "source": [
    "This, again, is also implemented as the RMSProp class in classes.py. So, now lets run our model with the RMSProp optimizer and a 1e-4 decay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e857d55952540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer as Adagrad with a decay\n",
    "optimizer = RMSProp(lr=0.02, decay=1e-5, rho=0.999)\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}, lr: {optimizer.lr_curr}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.preUpdateParams()\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)\n",
    "    optimizer.postUpdateParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb446507d288e253",
   "metadata": {},
   "source": [
    "That's pretty good, but still not up to the level of SGD with momentum. So, we have one last optimizer to cover: Adam.\n",
    "\n",
    "## Section 7: Adam\n",
    "\n",
    "**Adam** is just short for *Adaptive Momentum*. It is currently the most widely used optimizer and is built atop RMSProp. It has the momentum concept from SGD added back in, meaning that, instead of applying gradients we're going to apply momentums like we did in the SGD optimizer with momentum, then apply a per-weight adaptive learning rate with the cache as done in RMSProp.\n",
    "\n",
    "Adam additionally adds a bias correction mechanism. But: this is not the layer's bias. The bias correction mechanism is applied to the cache and momentum, compensating for the initial zerod values before they warm up with initial steps. To achieve this correction, both momentum and caches are divided by $1-beta^{step}$. As this step raises, $beta^{step}$ approaches 0. As we know the limit of $x^{n}$ where 0>x<1 as n approaches infinity tends to 0. \n",
    "\n",
    "The same thing applies to the cache and the beta 2, where the starting value is 0.001 and approaches 1. Both beta1 and beta2 divided the momentums in the cache. Division by a fraction causes them to be multiple times bigger, significantly speeding up training in the initial stages before both tables warm up during multiple initial steps.\n",
    "\n",
    "As the Adam code is based on that of RMSProp, we can just extend it's class, which I'll show below and implement in the classes.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82bfffe711d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleAdam(ExampleRMSProp):\n",
    "    #MODIFIED: add beta1 and beta2 \n",
    "    def __init__(self, lr=0.001, decay=0., epsilon=1e-7, beta1=0.9, beta2=0.999):\n",
    "        ...\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "    def updateParams(self, layer):\n",
    "        # Create cache arrays\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "            \n",
    "        # Update momentum\n",
    "        layer.weight_momentums = self.beta1 * layer.weight_momentums + (1-self.beta1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta1 * layer.bias_momentums + (1-self.beta1) * layer.dbiases\n",
    "        \n",
    "        # Correct momentum\n",
    "        weight_momentums_corrected = layer.weight_momentums / (1-self.beta1 ** (self.iterations+1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / (1-self.beta1 ** (self.iterations+1))\n",
    "        layer.weight_cache = self.beta2 * layer.weight_cache + (1-self.beta2) * layer.dweights**2\n",
    "        layer.bias_cache = self.beta2 * layer.bias_cache + (1-self.beta2) * layer.dbiases**2\n",
    "        \n",
    "        # Correct cache\n",
    "        weight_cache_corrected = layer.weight_cache / (1-self.beta2 ** (self.iterations+1))\n",
    "        bias_cache_corrected = layer.bias_cache / (1-self.beta2 ** (self.iterations+1))\n",
    "        \n",
    "        # Vanilla SGD parameter update + norm with square rooted cache\n",
    "        layer.weights += -self.lr_curr * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
    "        layer.biases += -self.lr_curr * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8cd222a26435",
   "metadata": {},
   "source": [
    "That is Adam! For what feels like the 20th time, full implementation is in the classes.py.\n",
    "\n",
    "Now, we can run our model for the final time -- now with the Adam optimizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c634cdf6a8076108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T22:30:12.301555Z",
     "start_time": "2025-06-20T22:30:10.200956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy:  0.307, loss:  1.099, lr: 0.05\n",
      "epoch: 100, accuracy:  0.750, loss:  0.630, lr: 0.04999752512250644\n",
      "epoch: 200, accuracy:  0.800, loss:  0.463, lr: 0.04999502549496326\n",
      "epoch: 300, accuracy:  0.823, loss:  0.399, lr: 0.049992526117345455\n",
      "epoch: 400, accuracy:  0.837, loss:  0.349, lr: 0.04999002698961558\n",
      "epoch: 500, accuracy:  0.873, loss:  0.326, lr: 0.049987528111736124\n",
      "epoch: 600, accuracy:  0.880, loss:  0.306, lr: 0.049985029483669646\n",
      "epoch: 700, accuracy:  0.870, loss:  0.280, lr: 0.049982531105378675\n",
      "epoch: 800, accuracy:  0.873, loss:  0.272, lr: 0.04998003297682575\n",
      "epoch: 900, accuracy:  0.877, loss:  0.253, lr: 0.049977535097973466\n",
      "epoch: 1000, accuracy:  0.890, loss:  0.246, lr: 0.049975037468784345\n",
      "epoch: 1100, accuracy:  0.883, loss:  0.236, lr: 0.049972540089220974\n",
      "epoch: 1200, accuracy:  0.890, loss:  0.227, lr: 0.04997004295924593\n",
      "epoch: 1300, accuracy:  0.927, loss:  0.220, lr: 0.04996754607882181\n",
      "epoch: 1400, accuracy:  0.913, loss:  0.214, lr: 0.049965049447911185\n",
      "epoch: 1500, accuracy:  0.923, loss:  0.215, lr: 0.04996255306647668\n",
      "epoch: 1600, accuracy:  0.927, loss:  0.204, lr: 0.049960056934480884\n",
      "epoch: 1700, accuracy:  0.907, loss:  0.202, lr: 0.04995756105188642\n",
      "epoch: 1800, accuracy:  0.927, loss:  0.199, lr: 0.049955065418655915\n",
      "epoch: 1900, accuracy:  0.933, loss:  0.191, lr: 0.04995257003475201\n",
      "epoch: 2000, accuracy:  0.930, loss:  0.187, lr: 0.04995007490013731\n",
      "epoch: 2100, accuracy:  0.903, loss:  0.193, lr: 0.0499475800147745\n",
      "epoch: 2200, accuracy:  0.930, loss:  0.188, lr: 0.0499450853786262\n",
      "epoch: 2300, accuracy:  0.920, loss:  0.181, lr: 0.0499425909916551\n",
      "epoch: 2400, accuracy:  0.917, loss:  0.181, lr: 0.04994009685382384\n",
      "epoch: 2500, accuracy:  0.930, loss:  0.175, lr: 0.04993760296509512\n",
      "epoch: 2600, accuracy:  0.937, loss:  0.173, lr: 0.049935109325431604\n",
      "epoch: 2700, accuracy:  0.923, loss:  0.172, lr: 0.049932615934796004\n",
      "epoch: 2800, accuracy:  0.940, loss:  0.168, lr: 0.04993012279315098\n",
      "epoch: 2900, accuracy:  0.940, loss:  0.166, lr: 0.049927629900459285\n",
      "epoch: 3000, accuracy:  0.923, loss:  0.172, lr: 0.049925137256683606\n",
      "epoch: 3100, accuracy:  0.937, loss:  0.167, lr: 0.04992264486178666\n",
      "epoch: 3200, accuracy:  0.923, loss:  0.166, lr: 0.04992015271573119\n",
      "epoch: 3300, accuracy:  0.937, loss:  0.160, lr: 0.04991766081847992\n",
      "epoch: 3400, accuracy:  0.943, loss:  0.160, lr: 0.049915169169995596\n",
      "epoch: 3500, accuracy:  0.923, loss:  0.174, lr: 0.049912677770240964\n",
      "epoch: 3600, accuracy:  0.923, loss:  0.170, lr: 0.049910186619178794\n",
      "epoch: 3700, accuracy:  0.940, loss:  0.160, lr: 0.04990769571677183\n",
      "epoch: 3800, accuracy:  0.933, loss:  0.159, lr: 0.04990520506298287\n",
      "epoch: 3900, accuracy:  0.937, loss:  0.156, lr: 0.04990271465777467\n",
      "epoch: 4000, accuracy:  0.930, loss:  0.158, lr: 0.049900224501110035\n",
      "epoch: 4100, accuracy:  0.940, loss:  0.153, lr: 0.04989773459295174\n",
      "epoch: 4200, accuracy:  0.940, loss:  0.154, lr: 0.04989524493326262\n",
      "epoch: 4300, accuracy:  0.937, loss:  0.166, lr: 0.04989275552200545\n",
      "epoch: 4400, accuracy:  0.943, loss:  0.152, lr: 0.04989026635914307\n",
      "epoch: 4500, accuracy:  0.943, loss:  0.149, lr: 0.04988777744463829\n",
      "epoch: 4600, accuracy:  0.947, loss:  0.148, lr: 0.049885288778453954\n",
      "epoch: 4700, accuracy:  0.950, loss:  0.147, lr: 0.049882800360552884\n",
      "epoch: 4800, accuracy:  0.950, loss:  0.147, lr: 0.04988031219089794\n",
      "epoch: 4900, accuracy:  0.950, loss:  0.146, lr: 0.049877824269451976\n",
      "epoch: 5000, accuracy:  0.950, loss:  0.146, lr: 0.04987533659617785\n",
      "epoch: 5100, accuracy:  0.947, loss:  0.145, lr: 0.04987284917103844\n",
      "epoch: 5200, accuracy:  0.950, loss:  0.145, lr: 0.04987036199399661\n",
      "epoch: 5300, accuracy:  0.933, loss:  0.149, lr: 0.04986787506501525\n",
      "epoch: 5400, accuracy:  0.943, loss:  0.146, lr: 0.04986538838405724\n",
      "epoch: 5500, accuracy:  0.937, loss:  0.147, lr: 0.049862901951085496\n",
      "epoch: 5600, accuracy:  0.947, loss:  0.143, lr: 0.049860415766062906\n",
      "epoch: 5700, accuracy:  0.950, loss:  0.142, lr: 0.0498579298289524\n",
      "epoch: 5800, accuracy:  0.943, loss:  0.143, lr: 0.04985544413971689\n",
      "epoch: 5900, accuracy:  0.947, loss:  0.140, lr: 0.049852958698319315\n",
      "epoch: 6000, accuracy:  0.930, loss:  0.151, lr: 0.04985047350472258\n",
      "epoch: 6100, accuracy:  0.940, loss:  0.143, lr: 0.04984798855888967\n",
      "epoch: 6200, accuracy:  0.950, loss:  0.139, lr: 0.049845503860783506\n",
      "epoch: 6300, accuracy:  0.943, loss:  0.140, lr: 0.049843019410367055\n",
      "epoch: 6400, accuracy:  0.947, loss:  0.144, lr: 0.04984053520760327\n",
      "epoch: 6500, accuracy:  0.947, loss:  0.138, lr: 0.049838051252455155\n",
      "epoch: 6600, accuracy:  0.940, loss:  0.146, lr: 0.049835567544885655\n",
      "epoch: 6700, accuracy:  0.933, loss:  0.142, lr: 0.04983308408485778\n",
      "epoch: 6800, accuracy:  0.947, loss:  0.142, lr: 0.0498306008723345\n",
      "epoch: 6900, accuracy:  0.943, loss:  0.144, lr: 0.04982811790727884\n",
      "epoch: 7000, accuracy:  0.940, loss:  0.138, lr: 0.04982563518965381\n",
      "epoch: 7100, accuracy:  0.947, loss:  0.137, lr: 0.049823152719422406\n",
      "epoch: 7200, accuracy:  0.940, loss:  0.138, lr: 0.049820670496547675\n",
      "epoch: 7300, accuracy:  0.950, loss:  0.135, lr: 0.04981818852099264\n",
      "epoch: 7400, accuracy:  0.947, loss:  0.136, lr: 0.049815706792720335\n",
      "epoch: 7500, accuracy:  0.940, loss:  0.135, lr: 0.0498132253116938\n",
      "epoch: 7600, accuracy:  0.930, loss:  0.150, lr: 0.04981074407787611\n",
      "epoch: 7700, accuracy:  0.950, loss:  0.133, lr: 0.049808263091230306\n",
      "epoch: 7800, accuracy:  0.953, loss:  0.133, lr: 0.04980578235171948\n",
      "epoch: 7900, accuracy:  0.950, loss:  0.133, lr: 0.04980330185930667\n",
      "epoch: 8000, accuracy:  0.950, loss:  0.131, lr: 0.04980082161395499\n",
      "epoch: 8100, accuracy:  0.950, loss:  0.132, lr: 0.04979834161562752\n",
      "epoch: 8200, accuracy:  0.947, loss:  0.131, lr: 0.04979586186428736\n",
      "epoch: 8300, accuracy:  0.950, loss:  0.131, lr: 0.04979338235989761\n",
      "epoch: 8400, accuracy:  0.930, loss:  0.153, lr: 0.04979090310242139\n",
      "epoch: 8500, accuracy:  0.947, loss:  0.133, lr: 0.049788424091821805\n",
      "epoch: 8600, accuracy:  0.950, loss:  0.130, lr: 0.049785945328062006\n",
      "epoch: 8700, accuracy:  0.950, loss:  0.129, lr: 0.0497834668111051\n",
      "epoch: 8800, accuracy:  0.943, loss:  0.135, lr: 0.049780988540914256\n",
      "epoch: 8900, accuracy:  0.950, loss:  0.129, lr: 0.0497785105174526\n",
      "epoch: 9000, accuracy:  0.950, loss:  0.129, lr: 0.04977603274068329\n",
      "epoch: 9100, accuracy:  0.947, loss:  0.129, lr: 0.04977355521056952\n",
      "epoch: 9200, accuracy:  0.943, loss:  0.135, lr: 0.049771077927074414\n",
      "epoch: 9300, accuracy:  0.937, loss:  0.137, lr: 0.0497686008901612\n",
      "epoch: 9400, accuracy:  0.947, loss:  0.130, lr: 0.04976612409979302\n",
      "epoch: 9500, accuracy:  0.950, loss:  0.130, lr: 0.0497636475559331\n",
      "epoch: 9600, accuracy:  0.950, loss:  0.128, lr: 0.049761171258544616\n",
      "epoch: 9700, accuracy:  0.950, loss:  0.128, lr: 0.0497586952075908\n",
      "epoch: 9800, accuracy:  0.947, loss:  0.129, lr: 0.04975621940303483\n",
      "epoch: 9900, accuracy:  0.950, loss:  0.126, lr: 0.049753743844839965\n"
     ]
    }
   ],
   "source": [
    "# Creating some training data used the spiral_data function\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create dense layer with 2 input features and 64 output features\n",
    "dense1 = DenseLayer(2, 64)\n",
    "\n",
    "# Use a relu activation\n",
    "activation1 = ReLU()\n",
    "\n",
    "# Create a dense layer for our output with 64 as an input and 3 as an output\n",
    "dense2 = DenseLayer(64, 3)\n",
    "\n",
    "# Use a softmax combined with ccel. for our output \n",
    "activationLoss = SoftMaxCategoricalCrossEntropy()\n",
    "\n",
    "# Initialize optimizer as Adagrad with a decay\n",
    "optimizer = Adam(lr=0.05, decay=5e-7)\n",
    "\n",
    "# Create the loop that trains our model in epochs\n",
    "for epoch in range(10000):\n",
    "    # Perform the forward pass, as shown previously\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = activationLoss.forward(dense2.output, y)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    predictions = np.argmax(activationLoss.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, accuracy: {accuracy: .3f}, loss: {loss: .3f}, lr: {optimizer.lr_curr}\")\n",
    "        \n",
    "    # Perform the backward pass\n",
    "    activationLoss.backward(activationLoss.output, y)\n",
    "    dense2.backward(activationLoss.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    # Use the optimizer and update the weights and biases\n",
    "    optimizer.preUpdateParams()\n",
    "    optimizer.updateParams(dense1)\n",
    "    optimizer.updateParams(dense2)\n",
    "    optimizer.postUpdateParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecac221ad5a3eb1",
   "metadata": {},
   "source": [
    "Here we have the best result that we've achieved thus far -- and it can't get much better! Adam has performed the best on this task, but it is recommended to start with Adam initially and then compare the other optimizers if you are not getting the expected (or hoped) results.\n",
    "\n",
    "While we achieved great results here, with an end accuracy of 95%, they may be a little bit *too* good. The next chapter will talk about the risks this may bring, but for now, life is good!.\n",
    "\n",
    "### Anyways, that's it for this chapter! Thanks for following along with my annotations of *Neural Networks from Scratch* by Kinsley and Kukiea! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
